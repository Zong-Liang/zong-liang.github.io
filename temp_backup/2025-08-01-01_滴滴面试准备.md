---
title: "01_滴滴面试准备"
date: 2025-06-01 00:00:01 +0800
categories: [JAVA后端项目, 黑马点评]
tags: [分布式, Redis]
pin: false
toc: true
math: true
---

## **1. String/StringBuffer/StringBuilder 区别**

这三者都用于处理字符串，但核心区别在于**可变性**和**线程安全性**。

- **String**: 它是**不可变**的 (immutable)。底层使用 `final` 修饰的字符数组存储，任何对 String 对象的操作（如拼接、截取）都会创建一个全新的 String 对象，原对象保持不变。这种特性使得 String 在多线程环境下是天然线程安全的，但也导致了在频繁修改字符串时会产生大量垃圾对象，效率较低。
- **StringBuffer**: 它是**可变**的，并且是**线程安全**的。它的方法（如 `append`、`insert`）都由 `synchronized` 关键字修饰，保证了在多线程环境下操作的原子性。但由于加锁会带来性能开销，所以在单线程环境下性能不如 StringBuilder。
- **StringBuilder**: 它也是**可变**的，但是**线程不安全**。它的 API 和 StringBuffer 完全兼容，但不保证同步。正因为没有锁的开销，它在单线程环境下执行效率是三者中最高的。

**总结一下选择策略：**

- 字符串不常变动：使用 **String**。
- 多线程环境下频繁修改字符串：使用 **StringBuffer**。
- 单线程环境下频繁修改字符串：使用 **StringBuilder**。

---

## **2. `String a=”ab”` `String b=”a”+”b”` a==b?**

结果是 **`true`**。

这是因为 Java 编译器在**编译期**会进行一个重要的优化。对于 `"a" + "b"` 这样的字面量拼接，编译器会直接计算出结果 `"ab"`。因此，`String b = "a" + "b";` 这行代码在编译后的字节码中实际上等同于 `String b = "ab";`。

在 Java 中，字符串字面量会被存储在**字符串常量池**中。

1.  `String a = "ab";` 执行时，JVM 会在字符串常量池中查找是否存在 `"ab"`。如果不存在，就创建一个并让 `a` 指向它；如果存在，`a` 就直接指向该地址。
2.  `String b = "a" + "b";` 经过编译期优化后，变成了 `String b = "ab";`。JVM 同样在常量池中查找 `"ab"`，此时发现已经存在（由第一步创建），于是 `b` 也指向了同一个地址。

因为 `a` 和 `b` 指向的是常量池中同一个对象的内存地址，所以 `a == b` 的结果为 `true`。

---

## **3. `==` 和 `equals` 的区别是什么？**

- **`==`**:
  - 对于基本数据类型，比较的是值。
  - 对于引用数据类型，比较的是对象的内存地址。
- **`equals`**:
  - 是 Object 类的方法，默认实现也是比较对象的内存地址。
  - 很多类（如 String、Integer 等）重写了 `equals` 方法，用来比较对象的内容是否相等。

---

## **4. 常用的 Java 集合**

Java 集合框架主要包含三大核心接口：`Collection`、`Map` 和 `Iterator`。其中 `Collection` 和 `Map` 是最主要的两大分支。

- **List (列表)**: 有序、可重复。

  - `ArrayList`: 基于动态数组实现，查询快（O(1)），增删慢（O(n)），线程不安全。
  - `LinkedList`: 基于双向链表实现，增删快（O(1)），查询慢（O(n)），线程不安全。
  - `Vector`: `ArrayList` 的线程安全版本，所有方法都加了 `synchronized`，性能较差，已不推荐使用。

- **Set (集合)**: 无序（大部分实现）、不可重复。

  - `HashSet`: 基于 `HashMap` 实现，通过键的唯一性保证元素的唯一性，无序。
  - `LinkedHashSet`: 继承自 `HashSet`，同时维护了一个双向链表，可以保证元素插入的顺序。
  - `TreeSet`: 基于红黑树（一种自平衡二叉查找树）实现，元素会自动排序。

- **Map (映射)**: 存储键值对(Key-Value)，Key 不可重复。
  - `HashMap`: 基于哈希表实现，线程不安全，key 和 value 都可以为 `null`。
  - `LinkedHashMap`: 继承自 `HashMap`，额外维护了链表，可以保证插入顺序或访问顺序。
  - `TreeMap`: 基于红黑树实现，key 会自动排序。
  - `Hashtable`: `HashMap` 的线程安全版本，所有方法加 `synchronized`，性能差，且 key 和 value 都不能为 `null`，已不推荐使用。
  - `ConcurrentHashMap`: 高效的线程安全 Map，是`Hashtable`的完美替代品。

---

## **5. 线程池的核心参数、工作原理和拒绝策略是什么？**

- **核心参数**:
  - `corePoolSize`: 核心线程数。
  - `maximumPoolSize`: 最大线程数。
  - `keepAliveTime`: 空闲线程存活时间。
  - `unit`: `keepAliveTime` 的时间单位。
  - `workQueue`: 任务队列，用于存放待执行的任务。
  - `threadFactory`: 线程工厂，用于创建线程。
  - `handler`: 拒绝策略，当任务队列和线程池都满了之后的处理策略。
- **工作原理**:
  1.  提交任务后，线程池会判断核心线程池是否已满，如果未满，则创建新线程执行任务。
  2.  如果核心线程池已满，则判断任务队列是否已满，如果未满，则将任务放入队列。
  3.  如果任务队列也已满，则判断线程池是否已达到最大线程数，如果未达到，则创建新线程执行任务。
  4.  如果线程池也已达到最大线程数，则触发拒绝策略。
- **拒绝策略**:
  - `AbortPolicy` (默认): 直接抛出 `RejectedExecutionException` 异常。
  - `CallerRunsPolicy`: 由提交任务的线程来执行该任务。
  - `DiscardPolicy`: 直接丢弃任务，不处理。
  - `DiscardOldestPolicy`: 丢弃队列中最老的任务，然后尝试重新提交当前任务。

---

## **6. HashMap 为何不安全，安全的是啥，1.8 前后分别用的是啥，1.8 之前用的什么锁**

- **HashMap 不安全的原因**: 在多线程环境下对 HashMap 进行 `put` 操作时，可能会导致数据覆盖、链表成环（JDK 1.7），造成 CPU 100%死循环，或者在扩容时导致数据丢失等问题。

- **安全的 Map**: `ConcurrentHashMap` 是 Java 并发包中提供的线程安全的 Map 实现，也是目前解决并发场景下 Map 需求的首选。

- **ConcurrentHashMap 在 JDK 1.8 前后的实现区别**:
  - **JDK 1.7 (及以前)**:
    - **底层结构**: `Segment` 数组 + `HashEntry` 数组 + 链表。
    - **锁机制**: **分段锁 (Segment Lock)**。它将整个 Map 分成多个`Segment`（默认 16 个），每个`Segment`相当于一个小型的`Hashtable`，内部有自己的`HashEntry`数组。当进行写操作时，只需要锁定该 key 对应的`Segment`即可，不同`Segment`之间的操作互不影响。这种设计的并发度就是`Segment`的数量。锁的类型是 `ReentrantLock`。
  - **JDK 1.8 (及以后)**:
    - **底层结构**: `Node` 数组 + 链表 / 红黑树。结构上与 JDK 1.8 的`HashMap`非常相似。
    - **锁机制**: 放弃了分段锁，改用 **CAS + `synchronized`**。当进行写操作时，它首先尝试使用 CAS 无锁操作去设置节点。如果 CAS 失败（说明有竞争），则会使用 `synchronized` 关键字锁住当前哈希桶的**头节点** (链表头节点或红黑树根节点)。这种锁的粒度更细，只锁住一个桶，而不是整个`Segment`，因此并发性能得到了极大的提升。

---

## **7. MySQL 有哪两个常用引擎？索引的存储方式有什么区别？MyISAM 支持外键吗？**

    - **常用引擎**: `InnoDB` 和 `MyISAM`。
    - **索引存储方式区别**:
      - **InnoDB**: 使用 B+树，索引文件和数据文件是存放在一起的（聚簇索引），主键索引的叶子节点存储了整行数据。
      - **MyISAM**: 使用 B+树，索引文件和数据文件是分开的（非聚簇索引），索引的叶子节点存储的是数据文件的地址指针。
    - **MyISAM 是否支持外键**: 不支持。

## **8. 什么是 B+树？什么是回表？**

    - **B+树**: 是 B 树的一种变体，非叶子节点只存储索引，不存储数据，所有数据都存储在叶子节点。叶子节点之间形成一个有序链表，便于范围查询。
    - **回表**: 在使用非主键索引（二级索引）查询时，如果查询的列不完全包含在索引中，那么在通过索引找到主键后，还需要根据主键再去主键索引中查找完整的行数据，这个过程就叫回表。

## **9. 索引失效的场景有哪些？所有模糊查询都不会使用索引吗？**

    - **索引失效场景**:
      - 在索引列上进行运算、函数、自动或手动类型转换。
      - `WHERE` 子句中使用 `OR`，`OR` 前的条件列是索引，而后面的列不是索引。
      - 使用 `LIKE` 进行模糊查询时，以 `%` 开头。
      - 查询条件中使用 `!=` 或 `<>`。
      - 复合索引没有遵循“最左前缀”原则。
    - **模糊查询与索引**: 并非所有模糊查询都不走索引。当 `LIKE` 查询的模式不以 `%` 开头时（例如 `like 'abc%'`），索引是可以被利用的。

## **10. 介绍一下 MVCC。**

    - MVCC (Multi-Version Concurrency Control)，多版本并发控制。是 `InnoDB` 引擎实现事务隔离级别的一种方式。它通过为每行数据添加隐藏的版本号字段，并在事务开始时创建一个读视图（Read View），使得在事务进行中，读操作不会阻塞写操作，写操作也不会阻塞读操作，从而提高了数据库的并发性能。它主要用来解决读-写冲突，实现了“读已提交”和“可重复读”隔离级别。

## **11. 介绍 MySQL 索引**

MySQL 索引是一种**数据结构**，类似于书籍的目录，旨在帮助数据库系统高效地获取数据。它的核心优势是能**极大提高数据查询速度**，但代价是会**降低插入、更新和删除的速度**，因为每次操作都需要同步维护索引，并且索引本身也需要占用磁盘空间。

- **从数据结构角度看**:

  - **B+树索引**: 这是最常用的索引类型，`InnoDB` 和 `MyISAM` 引擎都使用它。B+树的特点是所有数据都存在叶子节点，非叶子节点只存 key，且叶子节点之间有指针相连，非常适合范围查询。
  - **哈希索引**: `Memory` 引擎使用。基于哈希表实现，等值查询非常快（O(1)），但不支持范围查询和排序。
  - **全文索引**: 用于在文本中进行关键词搜索。

- **从物理存储角度看 (InnoDB)**:

  - **聚簇索引 (Clustered Index)**: 数据文件本身就是按主键索引的 B+树结构来组织的，叶子节点包含了完整的行数据。因此，每张表只能有一个聚簇索引，通常是主键。
  - **二级索引 (Secondary Index)**: 也叫非聚簇索引。它的叶子节点存储的不是行数据，而是**主键的值**。当使用二级索引查询时，如果需要的数据不在索引列中，会先找到主键，再用主键去聚簇索引中查找完整的行数据，这个过程称为**回表**。

- **从逻辑功能角度看**:
  - **主键索引**: 一种特殊的唯一索引，不允许有空值。
  - **唯一索引**: 索引列的值必须唯一，但允许有空值。
  - **普通索引**: 最基本的索引，没有任何限制。
  - **复合索引**: 在多个列上建立的索引，查询时需要遵循**最左前缀原则**才能有效利用。

---

## **12. SELECT 语句怎么执行的**

一条`SELECT`查询语句在 MySQL 中的执行流程大致如下：

1.  **连接器 (Connector)**: 客户端通过 TCP 连接到 MySQL 服务器，连接器负责处理连接、权限验证。
2.  **查询缓存 (Query Cache)**: (MySQL 8.0 已废弃) 在接收到查询后，会先检查查询缓存。如果能找到完全相同的 SQL 语句对应的缓存结果，就直接返回，不执行后续步骤。
3.  **分析器 (Analyzer)**:
    - **词法分析**: 将 SQL 语句打碎成一个个的单词（Token）。
    - **语法分析**: 根据语法规则判断 SQL 语句是否正确，并生成一个“语法树”。
4.  **优化器 (Optimizer)**: 这是 MySQL 的核心部分。优化器会根据语法树生成多种执行计划，并选择一个它认为成本最低的计划。比如，决定使用哪个索引，决定表连接的顺序等。
5.  **执行器 (Executor)**:
    - 首先检查用户是否有查询该表的权限。
    - 调用存储引擎提供的 API 来执行查询。它会根据优化器给出的执行计划，去打开表、获取数据。
    - 引擎将结果返回给执行器，执行器再将结果集返回给客户端。

---

## **13. UPDATE 语句怎么执行的**

`UPDATE` 语句的执行流程比 `SELECT` 更复杂，因为它涉及数据的修改和日志记录，尤其是在`InnoDB`引擎下：

1.  **执行器** 调用**存储引擎**的 API，找到需要更新的行。
2.  **存储引擎 (InnoDB)**:
    a. 首先将该行数据从磁盘读入到内存的 **Buffer Pool** 中。
    b. 在内存中执行更新操作。
    c. 记录更新的**撤销日志 (Undo Log)**，用于事务回滚和 MVCC。
    d. 记录更新后的**重做日志 (Redo Log)**，并将其状态置为 **prepare**。
3.  **执行器** 收到存储引擎操作成功的信号后，开始记录**二进制日志 (Binlog)**。
4.  **执行器** 将`Binlog`写入磁盘。
5.  **执行器** 调用存储引擎的接口，将刚才的`Redo Log`状态从 **prepare** 改为 **commit**。

这个**两阶段提交**（Redo Log 的 prepare 和 commit）是保证数据一致性的关键。它确保了即使在写入`Binlog`后、`Redo Log`提交前发生宕机，数据库也能通过`Redo Log`和`Binlog`的状态来判断事务是否应该被提交或回滚，从而保证了主从库之间的数据一致性。

---

## **14. binlog 、redolog**

`Redo Log` (重做日志) 和 `Binlog` (二进制日志) 是 MySQL 中两种非常重要的日志，但它们的作用和层次完全不同。

- **Redo Log (重做日志)**:

  - **层次**: `InnoDB` 存储引擎层。
  - **内容**: 物理日志。记录的是“在某个数据页的某个偏移量上做了什么修改”，比如“将第 X 页第 Y 个字节的值修改为 Z”。
  - **作用**: **保证事务的持久性 (Durability) 和实现崩溃恢复 (Crash Recovery)**。MySQL 为了提高性能，会先将数据修改记录在内存的 Buffer Pool 中，而不是立即写入磁盘。`Redo Log`就是为了防止在数据写入磁盘前 MySQL 宕机导致数据丢失。有了它，即使宕机，重启后也可以根据`Redo Log`恢复到宕机前的状态。
  - **特点**: 循环写入，文件大小固定。

- **Binlog (二进制日志)**:
  - **层次**: MySQL Server 层，所有存储引擎共享。
  - **内容**: 逻辑日志。记录的是原始的 SQL 语句或者行的变更信息（Row 格式）。
  - **作用**: **用于数据恢复和主从复制**。数据库管理员可以通过`Binlog`恢复到某个时间点的数据。在主从架构中，从库通过读取主库的`Binlog`来同步数据。
  - **特点**: 追加写入，文件写满后会生成新文件。

**核心区别**: `Redo Log`保证的是`InnoDB`自身的数据不会因宕机丢失，而`Binlog`保证的是整个 MySQL 数据库的功能（如复制和恢复）。它们通过两阶段提交机制协同工作，确保数据一致性。

---

## **15. MySQL 的隔离级别，解决了什么问题，可重复读解决了幻读？**

MySQL 定义了四种标准的 SQL 隔离级别，用于解决并发事务中可能出现的问题：

1.  **读未提交 (Read Uncommitted)**:
    - **解决问题**: 无。
    - **存在问题**: **脏读** (一个事务读到另一个事务未提交的数据)、**不可重复读**、**幻读**。基本不用。
2.  **读已提交 (Read Committed)**: Oracle 等数据库的默认级别。
    - **解决问题**: **脏读**。
    - **存在问题**: **不可重复读** (一个事务内两次读取同一数据，结果不同)、**幻读**。
3.  **可重复读 (Repeatable Read)**: MySQL `InnoDB` 引擎的默认级别。
    - **解决问题**: **脏读**、**不可重复读**。
    - **存在问题**: 理论上存在**幻读** (一个事务内两次查询符合某个范围的记录，结果集数量不同)。
4.  **串行化 (Serializable)**:
    - **解决问题**: **脏读**、**不可重复读**、**幻读**。通过对所有读写操作加锁实现，并发性能极差。

**可重复读是否解决了幻读？**

这是一个经典问题。答案是：**在特定场景下，`InnoDB` 的可重复读隔离级别很大程度上解决了幻读问题**。

- `InnoDB` 实现可重复读，主要依赖**MVCC (多版本并发控制)**。当事务开启时，会创建一个一致性读视图 (Read View)，后续的所有读操作（快照读，即普通`SELECT`）都基于这个视图，因此不会看到其他事务新插入的数据，从而避免了幻读。
- 但是，对于**当前读**（如 `SELECT ... FOR UPDATE`、`UPDATE`、`DELETE`），MVCC 是无效的。为了解决这种场景下的幻读，`InnoDB` 引入了**间隙锁 (Gap Lock)** 和 **临键锁 (Next-Key Lock)**。这些锁会锁住一个范围，防止其他事务在这个范围内插入新的数据。

**结论**: `InnoDB`通过`MVCC` + `间隙锁`的组合，在默认的“可重复读”隔离级别下，基本杜绝了幻读的发生，使其行为接近于“串行化”级别，但性能更高。

---

## **16. 介绍 Spring IOC 和 AOP**

`IOC` 和 `AOP` 是 Spring 框架的两大核心支柱。

- **IOC (Inversion of Control) 控制反转**:

  - **核心思想**: 将对象的创建和依赖关系的管理权，从程序员手中**反转**给 Spring 容器。
  - **实现方式**: 主要通过**依赖注入 (DI, Dependency Injection)** 来实现。程序员不再需要通过 `new` 关键字手动创建对象，而是在配置文件（XML）或通过注解（如 `@Autowired`）声明对象之间的依赖关系，由 Spring 容器在运行时自动创建对象并注入依赖。
  - **好处**:
    1.  **解耦**: 大大降低了组件之间的耦合度。
    2.  **易于维护和测试**: 组件可以独立测试，替换实现也变得非常容易。
    3.  **方便整合**: Spring 容器可以方便地整合各种第三方框架和技术。

- **AOP (Aspect-Oriented Programming) 面向切面编程**:
  - **核心思想**: 一种编程范式，旨在将那些横切多个业务模块的通用功能（如日志记录、事务管理、权限控制）从业务逻辑中**分离**出来，形成可重用的“切面”。
  - **实现方式**: 基于**动态代理**技术。
    - 如果目标对象实现了接口，Spring 默认使用**JDK 动态代理**。
    - 如果目标对象没有实现接口，则使用**CGLIB**来创建子类作为代理。
  - **核心概念**:
    - **切面 (Aspect)**: 通用功能的模块化封装。
    - **通知 (Advice)**: 切面在特定连接点执行的动作（如前置通知、后置通知）。
    - **连接点 (Join Point)**: 程序执行过程中可以插入切面的点（如方法调用）。
    - **切点 (Pointcut)**: 定义了“在哪些连接点上应用通知”的规则。
  - **好处**: 提高了代码的模块化程度，让业务逻辑更纯粹，通用功能更易于维护和复用。

---

## **17. AOP 事务失效的场景，this 方法调用为啥失效**

Spring 的声明式事务（`@Transactional`）是基于 AOP 实现的，因此 AOP 失效的场景通常也会导致事务失效。

**常见失效场景**:

1.  **注解用在非 `public` 方法上**: `@Transactional` 只能用于 `public` 方法，因为代理类无法覆盖 `protected`、`private` 或包级可见的方法。
2.  **方法内部调用 (this 方法调用)**: 这是最经典、最常被问到的场景。
3.  **异常被 `try-catch` 捕获**: 如果事务方法内部捕获了异常并且没有重新抛出，Spring 将无法感知到异常，导致事务不会回滚。
4.  **数据库引擎不支持事务**: 使用 `MyISAM` 引擎的表不支持事务。
5.  **不正确的传播行为配置**: 例如，将 `propagation` 设置为 `NOT_SUPPORTED`。

**`this` 方法调用为什么会失效？**

- **根本原因**: **调用没有经过代理对象**。
- **详细解释**: Spring AOP 的本质是为目标对象创建一个代理对象，事务管理等切面逻辑是织入到这个代理对象中的。当外部代码调用一个 Bean 的 `@Transactional` 方法时，它实际调用的是代理对象的方法，代理对象会在调用真实方法前后开启和提交/回滚事务。
- 但是，如果在一个没有 `@Transactional` 注解的方法 A 内部，通过 `this.B()` 的方式去调用同一个类中有 `@Transactional` 注解的方法 B，这个调用是目标对象**内部的、直接的方法调用**。它没有经过 Spring 容器生成的代理对象，而是直接使用了 `this` 引用，因此 AOP 的代理逻辑（事务切面）完全没有机会介入，方法 B 的事务自然也就失效了。

**解决方法**:

- 将方法 B 移到另一个 Bean 中，通过注入该 Bean 来调用。
- 在当前类中注入自己（AopContext.currentProxy()），通过代理对象来调用方法 B。

## **18. `@Autowired` 和 `@Resource` 的区别是什么？各自优先什么？**

- **区别**:
  - `@Autowired` 是 Spring 提供的注解，默认按类型（byType）装配。
  - `@Resource` 是 JSR-250 规范的注解，默认按名称（byName）装配。
- **优先级**:
  - `@Autowired`: 默认按类型查找，如果找到多个，再按名称查找。
  - `@Resource`: 默认按名称查找，如果找不到，再按类型查找。

## **19. `@Autowired` 如果想按名称（byName）装配，需要配合新的注解吗？`@Qualifier` 是干什么的？**

- 是的，需要配合 `@Qualifier` 注解。
- `@Qualifier`: 当有多个同一类型的 Bean 时，可以使用 `@Qualifier("beanName")` 来明确指定要注入哪一个 Bean。

## **20. AOP 的底层是什么？两个动态代理的区别？它们代理的对象有什么区别？**

- **AOP 底层**: AOP (Aspect-Oriented Programming) 的底层是通过动态代理技术实现的。
- **两种动态代理**:
  - **JDK 动态代理**: 基于接口实现。它要求目标类必须实现一个或多个接口。代理对象和目标对象都实现了相同的接口。
  - **CGLIB 动态代理**: 基于继承实现。它通过创建目标类的子类作为代理对象，因此不要求目标类实现接口。
- **代理对象区别**:
  - JDK 动态代理只能代理实现了接口的类。
  - CGLIB 可以代理未实现接口的类。如果一个类是 `final` 的，则无法被 CGLIB 代理。

---

## **21. Redis 用过哪些数据结构**

Redis 提供了多种高性能的数据结构，我在项目中主要使用过以下几种：

- **String (字符串)**: 这是最基础的数据类型。常用于缓存用户信息、Session、文章计数（`INCR`原子递增）等。它还可以存储二进制数据，如图片。
- **Hash (哈希)**: 类似于 Java 中的`HashMap`，适合存储对象。比如，存储一个用户对象，可以将其 ID 作为 key，各个属性（如 name, age）作为 field 和 value。相比于将对象序列化成 JSON 字符串存入 String 类型，Hash 可以方便地对单个字段进行读写，更节省网络流量。
- **List (列表)**: 是一个双向链表，可以从头尾两端进行 Push/Pop 操作。常用于实现消息队列（`LPUSH`生产，`RPOP`消费）、文章列表、粉丝列表等。
- **Set (集合)**: 无序、唯一的元素集合。类似于 Java 的`HashSet`。常用于实现共同关注、抽奖系统（`SPOP`随机弹出一个元素）、标签系统等。可以方便地进行交集、并集、差集运算。
- **ZSet (Sorted Set, 有序集合)**: 在 Set 的基础上，为每个元素关联了一个`score`（分数），并根据分数进行排序。非常适合实现排行榜（如积分榜、热销榜）、延迟队列（用时间戳作为 score）等场景。

此外，Redis 还有一些高级数据结构，如 **Bitmap**（位图，用于用户签到、在线状态统计）、**HyperLogLog**（用于基数统计，如页面 UV）、**GEO**（地理空间，用于附近的人功能）。

---

## **22. Redis 为什么快？任何时候都是单线程的吗？**

- **快的原因**:
  1.  **纯内存操作**: 数据存储在内存中，读写速度非常快。
  2.  **单线程模型**: 避免了多线程上下文切换和锁竞争带来的开销。
  3.  **I/O 多路复用**: 使用非阻塞 I/O 模型（如 epoll），可以高效地处理大量并发连接。
  4.  **高效的数据结构**: 内部实现了多种优化的数据结构，如简单动态字符串、哈希表、跳表等。
- **是否总是单线程**: Redis 的核心网络模型和键值对操作是单线程的。但是在某些后台处理上，如 RDB 持久化（`bgsave`）和 AOF 重写（`bgrewriteaof`），Redis 会 fork 出子进程来执行，避免阻塞主线程。

---

## **23. RDB 和 AOF**

RDB 和 AOF 是 Redis 的两种持久化机制，用于在 Redis 服务器重启后恢复数据。

- **RDB (Redis Database)**:

  - **原理**: **快照 (Snapshot)**。在指定的时间间隔内（如每 5 分钟有 100 次写入），Redis 会`fork`一个子进程，将当前内存中的数据完整地生成一个快照文件（`dump.rdb`）。
  - **优点**:
    1.  生成的是一个紧凑的二进制文件，非常适合备份和灾难恢复。
    2.  恢复速度快，直接加载到内存即可。
    3.  由子进程进行持久化，对主进程性能影响小。
  - **缺点**:
    1.  实时性差，如果两次快照之间 Redis 宕机，会丢失这段时间的数据。
    2.  数据集大时，`fork`子进程可能会消耗较多时间和内存。

- **AOF (Append Only File)**:
  - **原理**: **日志追加**。将 Redis 服务器执行过的所有**写命令**都以文本形式追加到 AOF 文件的末尾。服务器重启时，会重新执行一遍 AOF 文件中的命令来恢复数据。
  - **优点**:
    1.  数据安全性更高。可以配置为每秒同步（`everysec`），最多只会丢失 1 秒的数据。
    2.  日志文件可读性强，易于理解和修复。
  - **缺点**:
    1.  AOF 文件通常比 RDB 文件大。
    2.  恢复速度比 RDB 慢，因为需要重放所有写命令。
    3.  运行效率通常比 RDB 略低，因为每次写操作都需要记录日志。

**选择与结合**:

- 在生产环境中，通常会**同时开启 RDB 和 AOF**。这样既能保证数据的安全性（AOF），又能方便地进行备份和快速恢复（RDB）。当两者同时存在时，Redis 会优先使用 AOF 文件进行数据恢复。

---

## **24. 什么是缓存三兄弟（缓存穿透、击穿、雪崩）？**

- **缓存穿透**: 查询一个数据库和缓存中都不存在的数据，导致每次请求都直接打到数据库上。
- **缓存击穿**: 一个热点 Key 在缓存中失效的瞬间，大量的并发请求直接访问数据库。
- **缓存雪崩**: 大量缓存 Key 在同一时间集体失效，导致大量请求直接打到数据库上。

---

## **25. Java 基本类型和封装类区别，分别存在哪**

**核心区别**:

| 特性       | 基本数据类型 (Primitive Types)              | 包装类 (Wrapper Classes)                                                    |
| :--------- | :------------------------------------------ | :-------------------------------------------------------------------------- |
| **本质**   | Java 语言内置的关键字                       | 普通的类，是基本类型的对象封装                                              |
| **默认值** | 有默认值（如`int`为 0, `boolean`为`false`） | `null`                                                                      |
| **用途**   | 主要用于数值计算和存储                      | 1. 参与面向对象编程<br>2. 用于集合框架（泛型必须是对象）<br>3. 支持`null`值 |
| **比较**   | 使用 `==` 比较值                            | `==` 比较内存地址，`.equals()` 比较值                                       |

**内存存储位置**:

这是一个经典且容易混淆的问题，需要分情况讨论：

- **作为局部变量 (在方法内声明)**:

  - **基本类型**: 它的**值**直接存储在**Java 虚拟机栈 (Stack)** 的栈帧中。
  - **包装类**: 它的**引用 (reference)** 存储在**栈**中，而对象实例本身存储在**堆 (Heap)** 中。

- **作为成员变量 (在类中声明)**:
  - 无论**基本类型**还是**包装类**，它们都是对象的一部分，因此都存储在**堆 (Heap)** 中，作为对象实例数据的一部分。

**自动装箱/拆箱 (Autoboxing/Unboxing)**:
从 JDK 1.5 开始，Java 引入了自动装箱和拆箱机制，使得基本类型和包装类之间的转换变得透明。

- **自动装箱**: `Integer i = 10;` (自动将`int`转换为`Integer`)
- **自动拆箱**: `int n = i;` (自动将`Integer`转换为`int`)

需要注意的是，自动装箱/拆箱可能会因为创建不必要的对象而带来性能开销，并且在特定场景下（如循环中）或与`==`比较时，需要特别小心潜在的`NullPointerException`和缓存问题（如`Integer`在-128 到 127 之间的缓存）。

---

## **26. TCP 和 UDP 的区别？**

- **TCP (Transmission Control Protocol)**:
  - **连接性**: 面向连接。
  - **可靠性**: 可靠，保证数据按序、无差错地到达。
  - **速度**: 传输效率相对较低。
  - **头部开销**: 头部较大。
  - **应用场景**: 文件传输、邮件发送等要求高可靠性的场景。
- **UDP (User Datagram Protocol)**:
  - **连接性**: 无连接。
  - **可靠性**: 不可靠，不保证数据能否到达、是否按序。
  - **速度**: 传输效率高。
  - **头部开销**: 头部小。
  - **应用场景**: 视频直播、在线游戏等对实时性要求高、对少量丢包不敏感的场景。

---

## 手撕双重校验锁（DCL）的单例模式?

```java
public class Singleton {

    // 使用 volatile 保证多线程环境下的可见性和禁止指令重排
    private static volatile Singleton instance;

    // 私有化构造函数，防止外部直接创建实例
    private Singleton() {}

    // 提供公共的静态方法获取实例
    public static Singleton getInstance() {
        // 第一次检查，如果不为null，则直接返回，避免不必要的同步
        if (instance == null) {
            // 同步代码块，保证线程安全
            synchronized (Singleton.class) {
                // 第二次检查，防止多个线程同时进入第一个if，并创建多个实例
                if (instance == null) {
                    instance = new Singleton();
                }
            }
        }
        return instance;
    }
}
```

---

## 手撕反转链表 II

```java
/**
 * Definition for singly-linked list.
 * public class ListNode {
 *     int val;
 *     ListNode next;
 *     ListNode() {}
 *     ListNode(int val) { this.val = val; }
 *     ListNode(int val, ListNode next) { this.val = val; this.next = next; }
 * }
 */
class Solution {
    public ListNode reverseBetween(ListNode head, int left, int right) {
        // 如果 left 和 right 相同，或者链表为空/只有一个节点，则无需反转
        if (left == right || head == null || head.next == null) {
            return head;
        }

        // 创建一个虚拟头节点，以应对 left=1 的情况
        ListNode dummy = new ListNode(-1);
        dummy.next = head;

        // 1. 定位到待反转区域的前一个节点 pre
        ListNode pre = dummy;
        for (int i = 0; i < left - 1; i++) {
            pre = pre.next;
        }

        // start 是待反转区域的第一个节点
        ListNode start = pre.next;

        // then 用于指向每次需要移动的节点
        ListNode then = start.next;

        // 2. 使用头插法进行反转
        // 一共需要执行 right - left 次操作
        for (int i = 0; i < right - left; i++) {
            // 将 start 的下一个节点 (then) 移动到 pre 的后面

            // 步骤 1: start 跳过 then，指向 then 的下一个节点
            start.next = then.next;

            // 步骤 2: then 的 next 指向 pre 的下一个节点 (即反转后的头部)
            then.next = pre.next;

            // 步骤 3: pre 的 next 指向 then，完成插入
            pre.next = then;

            // 步骤 4: 更新 then，为下一次循环做准备
            then = start.next;
        }

        // 3. 返回最终的头节点
        return dummy.next;
    }
}
```

---

## 手撕十万个数里找最小的十个？

```java
import java.util.PriorityQueue;
import java.util.Comparator;
import java.util.Arrays;

public class FindTopKSmallest {

    /**
     * 从给定的数组中找出最小的 K 个数。
     *
     * @param arr 输入的整型数组
     * @param k   需要找出的最小元素的数量
     * @return 包含最小 K 个数的数组，不保证有序
     */
    public static int[] getLeastNumbers(int[] arr, int k) {
        // 边界条件处理
        if (k == 0 || arr == null || arr.length == 0) {
            return new int[0];
        }
        if (k >= arr.length) {
            return arr;
        }

        // 创建一个最大堆（大顶堆）。
        // 使用 Lambda 表达式 (o2, o1) -> o2 - o1 来实现降序排列。
        // 或者使用 Collections.reverseOrder()
        PriorityQueue<Integer> maxHeap = new PriorityQueue<>((o1, o2) -> o2 - o1);

        // 遍历数组
        for (int num : arr) {
            if (maxHeap.size() < k) {
                // 如果堆还没满，直接放入
                maxHeap.offer(num);
            } else if (num < maxHeap.peek()) {
                // 如果当前数字比堆顶元素（当前K个数中的最大值）小
                // 就把堆顶元素弹出，把当前数字放入
                maxHeap.poll();
                maxHeap.offer(num);
            }
        }

        // 将堆中的元素转换为数组返回
        int[] result = new int[k];
        for (int i = 0; i < k; i++) {
            result[i] = maxHeap.poll();
        }

        return result;
    }

    public static void main(String[] args) {
        // 模拟十万个数
        int[] largeArray = new int[100000];
        for (int i = 0; i < largeArray.length; i++) {
            // 为了演示，我们让最小的10个数是 0 到 9
            largeArray[i] = largeArray.length - i -1;
        }
        // 打乱数组，增加随机性
        // (实际场景中数据是无序的)

        System.out.println("从十万个数中找出最小的10个数：");

        int[] smallestTen = getLeastNumbers(largeArray, 10);

        // 为了方便查看，对结果进行排序
        Arrays.sort(smallestTen);

        System.out.println(Arrays.toString(smallestTen)); // 应该输出 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
    }
}
```
